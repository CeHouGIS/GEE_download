{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d743c3",
   "metadata": {},
   "source": [
    "## 将下载好的ipynb文件重新分配至以格网为单元的文件夹里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "708d275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702119a5",
   "metadata": {},
   "source": [
    "1. 整理下载好图片的metadata (存储到/nas/houce/Alphaearth_embedding/metadata/downloaded_grid_cells_5x5_merged.csv中)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24e9250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_download_records = glob(\"/nas/houce/Alphaearth_embedding/GEE_extracted/*/metadata/*_grid_cells.csv\")\n",
    "for i, file_path in enumerate(all_download_records):\n",
    "    if i == 0:\n",
    "        all_download_file_df = pd.read_csv(file_path)\n",
    "    else:\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        all_download_file_df = pd.concat([all_download_file_df, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "all_download_file_df['geometry'] = all_download_file_df.apply(\n",
    "    lambda row: Polygon([\n",
    "        (row['lon_min'], row['lat_min']),\n",
    "        (row['lon_min'], row['lat_max']),\n",
    "        (row['lon_max'], row['lat_max']),\n",
    "        (row['lon_max'], row['lat_min']),\n",
    "        (row['lon_min'], row['lat_min'])\n",
    "    ]), axis=1\n",
    ")\n",
    "all_download_file_gdf = gpd.GeoDataFrame(all_download_file_df, geometry='geometry', crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7408109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用已知的total_boundary生成5x5度的网格\n",
    "lon_min, lat_min, lon_max, lat_max = [-180, -90, 180, 90]  # total_boundary\n",
    "\n",
    "lon_bins = np.arange(np.floor(lon_min), np.ceil(lon_max), 5)\n",
    "lat_bins = np.arange(np.floor(lat_min), np.ceil(lat_max), 5)\n",
    "\n",
    "grid_polygons = []\n",
    "for lon1 in lon_bins:\n",
    "    for lat1 in lat_bins:\n",
    "        lon2 = lon1 + 5\n",
    "        lat2 = lat1 + 5\n",
    "        poly = Polygon([\n",
    "            (lon1, lat1),\n",
    "            (lon1, lat2),\n",
    "            (lon2, lat2),\n",
    "            (lon2, lat1),\n",
    "            (lon1, lat1)\n",
    "        ])\n",
    "        grid_polygons.append({'lon_min': lon1, 'lon_max': lon2, 'lat_min': lat1, 'lat_max': lat2, 'geometry': poly})\n",
    "\n",
    "grid_gdf = gpd.GeoDataFrame(grid_polygons, geometry='geometry', crs=\"EPSG:4326\")\n",
    "grid_gdf['folder_name'] = grid_gdf.apply(\n",
    "    lambda row: f\"grid_{int(row['lon_min'])}_{int(row['lat_min'])}_{int(row['lon_max'])}_{int(row['lat_max'])}\", axis=1\n",
    ")\n",
    "grid_gdf_merged = grid_gdf[['folder_name','geometry']].sjoin(all_download_file_gdf, how='left', predicate='intersects', lsuffix='grid', rsuffix='download')\n",
    "# unique_grid_gdf_merged = grid_gdf_merged[grid_gdf_merged['index_download'].notna()].drop_duplicates(subset='file_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26ba70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AEF_file_paths = pd.DataFrame(glob(\"/nas/houce/Alphaearth_embedding/GEE_extracted/Africa_grid_*/*/*.tif\"), columns=['file_path'])\n",
    "AEF_file_paths2 = pd.DataFrame(glob(\"/nas/houce/Alphaearth_embedding/GEE_extracted/Africa_grid_*/*.tif\"), columns=['file_path'])\n",
    "AEF_file_paths_all = pd.concat([AEF_file_paths, AEF_file_paths2], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "AEF_transferred_file_paths = pd.DataFrame(glob(\"/nas/houce/Alphaearth_embedding/AEF_tiles/*/*/*.tif\"), columns=['file_path_copied'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71baa6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "AEF_file_paths_all['grid_name'] = AEF_file_paths_all['file_path'].apply(lambda x: x.split(\"/\")[-1][20:-26])\n",
    "AEF_transferred_file_paths['grid_name'] = AEF_transferred_file_paths['file_path_copied'].apply(lambda x: x.split(\"/\")[-1][20:-26])\n",
    "AEF_transferred_file_paths['start_time'] = AEF_transferred_file_paths['file_path_copied'].apply(lambda x: x.split(\"_\")[-2])\n",
    "AEF_transferred_file_paths['end_time'] = AEF_transferred_file_paths['file_path_copied'].apply(lambda x: x.split(\"_\")[-1][:-4])\n",
    "\n",
    "AEF_file_paths_all_merged = grid_gdf_merged.merge(AEF_file_paths_all, on='grid_name', how='left')\n",
    "AEF_file_paths_all_merged = AEF_file_paths_all_merged.merge(AEF_transferred_file_paths, on='grid_name', how='left')\n",
    "# all_AEF_files_merged = AEF_transferred_file_paths.merge(AEF_file_paths_all_merged, on='grid_name', how='left')\n",
    "AEF_file_paths_all_merged.to_file(\"/nas/houce/Alphaearth_embedding/metadata/all_grid_cells_5x5_merged.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840f33f",
   "metadata": {},
   "source": [
    "3. 转移图片到指定目录下，并删除源文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d8b6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "updated_AEF_path = AEF_file_paths_all_merged[AEF_file_paths_all_merged['file_path'].notna()].drop_duplicates(subset='file_path')\n",
    "for i, row in tqdm(updated_AEF_path.iterrows(), total=updated_AEF_path.shape[0]):\n",
    "    if pd.isna(row['file_path_copied']):\n",
    "        src_path = row['file_path']\n",
    "        folder_name = row['folder_name']\n",
    "        dest_dir = os.path.join(f\"/nas/houce/Alphaearth_embedding/AEF_tiles/{row['file_path'].split('_')[-2][:4]}\", folder_name)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        dest_path = os.path.join(dest_dir, os.path.basename(src_path))\n",
    "        try:\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            os.remove(src_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {src_path} to {dest_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fbdea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dirs = [d for d in glob(\"/nas/houce/Alphaearth_embedding/AEF_tiles/*\") if os.path.isdir(d)]\n",
    "\n",
    "# for path in tqdm(all_dirs):\n",
    "#     if not os.listdir(path):\n",
    "#         os.rmdir(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
